{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training BERT-Masked language Modeling\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-5LaHPyiGiiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective: The objective is to learn contextual representations for each token in the sentence. By predicting the masked tokens, the model learns to understand the relationships between words and their context."
      ],
      "metadata": {
        "id": "NODcOFWjaYxm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg6ZrP5t0rab"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "\n",
        "text = (\"After Abraham Lincoln won the November 1860 presidential [MASK] on an anti-slavery platform,\"\n",
        "        \"an initial seven slave states declared their secession from the country to form the Confederacy.\"\n",
        "        \"War broke out in April 1861 when secessionist forces [MASK] Fort Sumter in South Carolina, just\"\n",
        "        \"over a month after Lincoln’s inauguration.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxP_8L_BGc2B",
        "outputId": "7dae9f89-66d4-4882-9f89-a6c9afdede29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Tokenization — tokenization is simple, we’ve already initialized a BertTokenizer, all we do now is tokenize our input text.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZCwWQIRc5Wxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(text, return_tensors = 'pt')\n",
        "inputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqd63eO4IKOq",
        "outputId": "b142bb6b-e1ce-48b3-c812-e353c80cbe97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVxj_BnqIbbL",
        "outputId": "5ee95e36-45f3-48ad-9100-406611434414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,   103,\n",
              "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
              "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
              "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
              "         22965,  2923,  2749,   103,  3481,  7680,  3334,  1999,  2148,  3792,\n",
              "          1010,  2074,  7840,  1037,  3204,  2044,  5367,  1521,  1055, 17331,\n",
              "          1012,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Create labels — The next step is easy, all we need to do here is clone our input_ids tensor into a new labels tensor. We’ll store this within the inputs variable too.\n",
        "\n"
      ],
      "metadata": {
        "id": "e9Cz1neG6Zri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs['labels'] = inputs.input_ids.detach().clone()"
      ],
      "metadata": {
        "id": "kSKuxz3iJHq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-86YEs6BJYmO",
        "outputId": "4ca62830-9c38-4dbb-f929-bb5d572c8784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,   103,\n",
              "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
              "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
              "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
              "         22965,  2923,  2749,   103,  3481,  7680,  3334,  1999,  2148,  3792,\n",
              "          1010,  2074,  7840,  1037,  3204,  2044,  5367,  1521,  1055, 17331,\n",
              "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,   103,\n",
              "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
              "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
              "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
              "         22965,  2923,  2749,   103,  3481,  7680,  3334,  1999,  2148,  3792,\n",
              "          1010,  2074,  7840,  1037,  3204,  2044,  5367,  1521,  1055, 17331,\n",
              "          1012,   102]])}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Masking — Now we need to mask a random selection of tokens in our input_ids tensor."
      ],
      "metadata": {
        "id": "kycPSLI27ao9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand = torch.rand(inputs.input_ids.shape)\n",
        "rand.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1yEstjVJgIY",
        "outputId": "ca590b25-8042-4f15-f1bf-0f715bfaba50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQah_GILJgVg",
        "outputId": "51a117c3-2a81-4c57-85b8-86149a956f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9800, 0.4654, 0.8416, 0.5915, 0.4076, 0.1713, 0.1807, 0.4198, 0.2993,\n",
              "         0.8467, 0.2840, 0.5585, 0.5689, 0.2452, 0.8187, 0.3732, 0.0650, 0.3584,\n",
              "         0.4466, 0.6148, 0.1163, 0.6702, 0.9334, 0.8375, 0.0562, 0.3789, 0.8837,\n",
              "         0.1572, 0.7461, 0.4864, 0.9627, 0.2180, 0.2571, 0.0957, 0.4333, 0.5788,\n",
              "         0.4881, 0.9576, 0.5462, 0.7327, 0.2004, 0.9011, 0.4318, 0.4640, 0.2967,\n",
              "         0.5253, 0.7868, 0.3934, 0.5132, 0.9406, 0.6474, 0.5167, 0.5293, 0.0209,\n",
              "         0.8263, 0.6886, 0.9791, 0.1328, 0.9305, 0.7169, 0.8051, 0.5472]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_arr = (rand > 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102)\n",
        "mask_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96Dpp5C4KEZI",
        "outputId": "74423279-8ae1-41d6-e38e-8068297080c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
              "         False,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
              "          True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
              "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "          True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
              "          True, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selection = torch.flatten(mask_arr[0].nonzero()).tolist()\n",
        "selection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2GUx3-CKEiK",
        "outputId": "67f33eea-9ad9-41ab-9d49-cf00bcc0f2ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 58,\n",
              " 59,\n",
              " 60]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.input_ids[0, selection] = 103\n",
        "inputs.input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QZz8MW3KEmV",
        "outputId": "0f015751-4667-4ed9-cf2c-6a0251e85592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
              "           103,   103,   103,   103,   103,   103,  1010,   103,   103,   103,\n",
              "          6658,   103,   103,   103, 22965,   103,   103,   103,   103,   103,\n",
              "           103,   103,   103,  2162,   103,   103,   103,   103,   103,   103,\n",
              "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
              "           103,   103,   103,  1037,   103,   103,   103,  1521,   103,   103,\n",
              "           103,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Calculate Loss — Our final step here no different from the typical model training process.\n",
        "\n"
      ],
      "metadata": {
        "id": "xrygXJlf8hpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "FmEDEzgEKEqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOLflfA7JgaS",
        "outputId": "82fa56e0-26d6-4182-aa97-b0496c3e34ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['loss', 'logits'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcrqyBU_P2rF",
        "outputId": "b999e4ae-2560-4bb1-ec91-de5607c6ac9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.2910, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tVVp4Oa5P22w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8aXAhLEDP27q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}